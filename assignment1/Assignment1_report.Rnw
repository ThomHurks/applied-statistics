\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{placeins}
\usepackage{longtable,framed}
\usepackage{amsmath,amssymb}

<<echo=FALSE, message=FALSE, results='hide'>>=
library(sas7bdat)
dataset = read.sas7bdat("assignment1.sas7bdat")
dataset = dataset[!is.nan(dataset$OUTCOME),]
dataset$LOGOUTCOME = log(dataset$OUTCOME)
dataset = dataset[!is.nan(dataset$OUTCOME),]
batchB0 = dataset[dataset$BATCH == "B0",]
batchB1 = dataset[dataset$BATCH == "B1",]
batchB2 = dataset[dataset$BATCH == "B2",]
batchB3 = dataset[dataset$BATCH == "B3",]
batchB4 = dataset[dataset$BATCH == "B4",]
batchB5 = dataset[dataset$BATCH == "B5",]
batchB6 = dataset[dataset$BATCH == "B6",]
batchB7 = dataset[dataset$BATCH == "B7",]

all_batches = unique(dataset$BATCH)
batches = all_batches[all_batches != "B0"]
@

\begin{document}
\title{Analysis of silicone contamination of batches}

\author{
\begin{minipage}{0.6\textwidth}
\centering
\begin{tabular}{l r}
Thom Hurks & \textit{0828691}\\
Puck Mulders & \textit{0737709}\\
Marijn van Knippenberg  & \textit{0676548}\\
Rik Coenders & \textit{0777004}
\end{tabular}
\end{minipage}
}

\date{\today}

\maketitle
\newpage
\tableofcontents
\newpage
\section{Introduction}
The health inspection has detected a silicone leakage in a machine used in a chemical production process. The leakage was detected in close vicinity of packed product, so the question is whether the product has been affected by the leakage. The machines are regularly inspected, and data on a batch produced before the previous inspection is available and is denoted as batch B0. Batches denoted B1 to B7 have been produced between the previous inspection and the current inspection and may have been affected by the leakage. The data consists of measurements of samples of units from the batches. The silicone that leaked is already part of the product itself, so it will always be present in the measured units to some extent. The goal of this report is to possibly identify the batches that were affected by the silicone leakage. If a batch is affected, we expect that the amount of silicones in a batch is somewhat higher in comparison with the unaffected batches. We therefore hypothesize that the affected batches have underwent a location shift such that the mean will be somewhat higher if compared with unaffected batches. \\\\
In the first section we describe which methods we use to find the affected batches. In the next section we will describe what the results of these methods are. Lastly, we will conclude which of the batches are affected. In this section we will also describe what the weaknesses and risks are of our investigation.
\newpage
\section{Methods}
To decide if any of the batches are affected, we perform both parametric and non-parametric tests. The parametric tests assume that the data is normally distributed, which means we must test for normality and if necessary transform the data. Non-parametric tests are generally less powerful than parametric tests, but can always be applied regardless of normality. With parametric tests one must be careful to draw conclusions about the original non-transformed data if the data needs to be transformed in order to meet the normality assumption. 
\subsection{Exploratory data analysis}
Before performing any parametric or non-parametric tests, we will first perform some standard statistical tests to gain some insight into the data. As a start, we will plot the data and calculate the mean, standard deviation, variance and median of each batch. After that, we will perform a Shapiro-Wilk test to see whether the non-transformed data is normal. We have formulated the null hypothesis as can be found in equation\ref{normal}:
\begin{align}
\label{normal}
\begin{cases}
H_0: B_i \sim \mathcal{N} & \quad \text{for } 1 \leq i \leq 7 \\
H_1: B_i\nsim \mathcal{N}  \\
\end{cases}
\end{align} 
We will reject the null hypothesis if the p-value $< 0.01$.
After that, we will perform a Wald-Wolfowitz Runs Test which has as a null hypothesis that each element in the sequence is independently drawn from the same random distribution which is expected if none of the batches are affected by silicones. We reject the null hypothesis if $p < 0.01$.
\subsection{Critical value}
Most of our hypotheses include testing all seven possibly affected batches. Because of this reason, we have to adjust the commonly used critical value of $0.05$ to make sure we do not reject the null hypothesis due to chance. Applying Bonferroni will give us a critical value of $\alpha=\frac{0,05}{7}=0,00714$, but since this value is quite low we may fail to reject the null hypotheses in cases where we actually want to; our goal is to identify the affected batches, so we can be a bit more strict and raise the alpha value slightly. As such, we will set the critical value to $0.01$.\\\\
For some tests, all the data at once will be investigated. At this point, we will not use a criticial value of $0.01$, but keep the critical value of $\alpha=0.05$. 
\subsection{Normal distribution}
\subsubsection{Investigating normality on transformed data}
We will perform a log-normal transformation on the data to modify the data such that the form of the data will shape towards a normal distribution. To check whether this helped, we will plot the transformed data and perform a Shapiro-Wilk test on each of the batches, which can be found in equation \ref{normal}. We will reject the null hypothesis if the p-value $<0.01$.
Besides a Shapiro-Wilk test, we will perform skwewness and kurtosis tests to test on where normality is violated. The critical value of a two-sided skewness test is 1,157, while the critical value of the kurtosis is 1,49. We will perform a Jarque-Bera test to see if it is appropriate to reject a normal distribution based on skewness and kurtosis. The null hypothesis is the same as with the Shapiro-Wilk test, which can be found in equation \ref{normal}. We will reject normality if the p-value $< 0.01$.
\subsubsection{T-test}
Because batch 0 is produced before the previous inspection where no leakage was discovered, we know that the distribution of the amount of silicones found in each batch should be similar to the amount of silicone in batch 0. To check whether they are similar, we will perform a one-sided t-test. We have chosen a one-sided test, since a leakage in silicones will cause the amount to be higher in the batches and thus we have to test only if the test is violated on one side. To perform a proper t-test, we have to know if the variances of the batches are equal. We check this by applying Barlett's test, which checks whether all the variances of the batches are equal to each other. This can be formulated as can be found in \ref{barlet}:
\begin{align}
\label{barlet}
\begin{cases}
H_0: \sigma_0 = \sigma_1 = \sigma_2 ... = \sigma_7  \\
H_1: \sigma_0 \neq \sigma_1 \neq \sigma_2 ... \neq \sigma_7
\end{cases}
\end{align}
We will reject the null hypothesis if p-value $< 0.05$. Based on these results, we will apply either a equal or unequal t-test. The hypotheses of the t-test is the following:
\begin{align}
\label{means}
\begin{cases}
H_0: \mu_0 \geq \mu_i & \quad \text{for } 1 \leq i \leq 7 \\
H_1: \mu_0 < \mu_i
\end{cases}
\end{align}
If the result of the t-test is less than $0.01$, we will reject the null hypothesis.
\subsubsection{Variance testing}
Besides performing a t-test, we will also perform some homogeneity tests to see whether the data also share the same characteristics. W will perform an F-test to see which batches have a variance similiar to batch 0. This can be formulated as can be found in equation \ref{ftest}:
\begin{align}
\label{ftest}
\begin{cases}
H_0: \sigma_0 = \sigma_i & \quad \text{for } 1 \leq i \leq 7 \\
H_1: \sigma_0 \neq \sigma_i
\end{cases}
\end{align}
We will reject the null hypothesis if the p-value $<0.01$.
\subsubsection{Outliers}
We will perform a Grubbs outlier test on the log-transformed to check whether there are any indications that one of the measurements has some incorrect value due to for example measurement errors. We will do this for both outliers on the left and right tail. Our null hypothesis is can be found in equation \ref{outlier}.We will reject the null hypothesis if the p-value $< 0.01$.
\begin{align}
\label{outlier}
\begin{cases}
H_0: \text{Batch}_i \text{ contains no outliers} & \quad \text{for } 1 \leq i \leq 7 \\
H_1: \text{Batch}_i \text{ contains outliers} \\
\end{cases}
\end{align}
We will reject the null hypothesis if the p-value$<0.01$.
\subsection{Non-parametric tests}
\subsubsection{Kolmogorov-Smirnov Test}
If the non-transformed data does not follow a normal distribution, we will also perform some non-parametric tests that do not assume a normal distribution. Such a parametric test is the Kolgomorov-Smirnov Test. For the two-sample version of this test, we need to make the following assumptions:
\begin{itemize}
  \item The two samples are independent.
  \item The outcomes are ordinal or numerical.
\end{itemize}
Since the results of the samples do not depend on each other, the first assumption can be made. Second, the outcomes are all numerical so the second assumption can be made too. We perform a two-sided test to get a general view of whether non-parametric testing picks up on any differiations between the distributions of batch 0 and the other batches. Our hypothesis is the following:
We will reject the null hypothesis when $p < 0.01$. Because batch 7 has a missing value, we have decided to impute the mean of batch 7 into the line with the missing value, to see whether this affects the test. The Kolmogorov-Smirnov test will not give the exact p-value due ties in the data, so it could be the case that the p-value retrieved from the test somewhat deviates from the real p-value. Because we have picked a somewhat high critical value, some bias of p-values can be handled.
\subsubsection{Wilcoxon Rank-Sum Test}
A second non-parametric test we will perform is the Wilcoxon Rank-Sum Test, which needs the assumption that both distributions are from an ordinal distribution. This implies that the data cannot contain any ties. Since we have some ties in the data, we will not get the exact p-value. Since our value does not contain a substantial amount of ties, the bias of the p-value will not be extremely high. Similiar as with the Kolmogorov-Smirnov test, we think that our critical value can handle some bias of the p-values calculated by the Wilcoxon Rank-Sum Test.
The hypotheses of the Wilcoxon Rank-Sum test can be found in equation \ref{wilcox}:
\begin{align}
\label{wilcox}
\begin{cases}
H_0: \text{Batch}_0 \text{ and batch}_i \text{ come from the same population} & \quad \text{for } 1 \leq i \leq 7 \\
H_1: \text{Batch}_0 \text{ and batch}_i \text{ come from a different population} 
\end{cases}
\end{align}
This null hypothesis indicates that the change that the median of $\text{batch}_0$ is larger than the median of $\text{batch}_1$ is the same as that the median of $\text{batch}_0$ is smaller than the median of $\text{batch}_1$. We will reject the null hypothesis if p-value $< 0.01$. 
\newpage
\section{Results}
\subsection{Exploratory data analysis}
The results of the standard data analysis can be found in the table below.
<<echo=FALSE, results='asis'>>=
means = list()
variances = list()
medians = list()
standevs = list()
for (batch in all_batches) {
  cur_batch = dataset[dataset$BATCH == batch,]$OUTCOME
  means[batch] = mean(cur_batch)
  medians[batch] = median(cur_batch)
  variances[batch] = var(cur_batch)
  standevs[batch] = sd(cur_batch)
}
metrics_frame = data.frame("mean" = unlist(means),
                           "median" = unlist(medians),
                           "variance" = unlist(variances),
                           "st-dev" = unlist(standevs))
library(xtable)
xtable(metrics_frame)
@
\FloatBarrier
We also discovered that batch seven has a missing value ("NA"). The statistical tests that we plan to do, do not require that the number of data points between batches is the same, and since there is only a single missing value in the whole dataset, we can simply remove the missing value.
The next step is to generate a normal QQ plot for batch 0 as an easy visual confirmation of normality.
<<figure1, fig.cap="QQ Plot of batch 0", fig.show="asis", fig.pos = "h!", echo=FALSE>>=
qqnorm(batchB0$OUTCOME)
qqline(batchB0$OUTCOME)
swtestB0 = shapiro.test(batchB0$OUTCOME)
@
\FloatBarrier
The normal QQ plot already seems to suggest that batch 0 is not normally distributed. When we also perform the Shapiro-Wilk normality test we can see the p-value $= \Sexpr{swtestB0$p.value} < 0.01$ so we can reject the null-hypothesis that the outcome is normally distributed.\\\\
Next we can generate a normal QQ plot for all batches 0 to 7. Of course generating this plot for multiple batches at once assumes that the units are somewhat consistent across different batches.
<<figure2, fig.cap="QQ Plot of batches 0 to 7", fig.show="asis", fig.pos = "h!", echo=FALSE>>=
qqnorm(dataset$OUTCOME)
qqline(dataset$OUTCOME)
@
\FloatBarrier
The normal QQ plot here too seems to suggest that the data is not normally distributed. We can again compute the Shapiro-Wilk test p-value for all batches to gather more information.
<<echo=FALSE, results='asis'>>=
shapiro_values = list()
for (batch in all_batches) {
  shapiro_values[batch] = shapiro.test(dataset[dataset$BATCH == batch,]$OUTCOME)$p.value
}
shapiro_frame = data.frame("p-value"=unlist(shapiro_values))
library(xtable)
xtable(shapiro_frame, digits=c(0,4))
@
\FloatBarrier
We can reject the normality null hypothesis for batches zero, five and six with p-values respectively $\Sexpr{shapiro_frame["B0",]}$, $\Sexpr{shapiro_frame["B5",]}$ and $\Sexpr{shapiro_frame["B6",]}$. We can also observe that for the other batches the p-values are not particularly high, the exception being batch 3 with a p-value of $\Sexpr{shapiro_frame["B3",]}$.
\FloatBarrier
\subsection{Normal distribution}
\subsubsection{Shapiro-Wilk on log-transformed data}
In the previous section we observed that the data does not seem to follow a normal distribution. In order to perform parametric tests that assume normality, we must then transform the data. We will transform the data using the well-known log transformation and then check for each batch what the p-value of the Shapiro-Wilk test is in order to confirm that the transformation had the desired effect.
<<echo=FALSE, results="asis">>=
sw_log_frame = data.frame(batch=c("B0", "B1", "B2", "B3", "B4", "B5", "B6", "B7"), 
                          "p-value"=c(shapiro.test(batchB0$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB1$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB2$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB3$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB4$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB5$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB6$LOGOUTCOME)$p.value,
                                      shapiro.test(batchB7$LOGOUTCOME)$p.value))
library(xtable)
xtable(sw_log_frame, digits=c(0,0,4))
@
\FloatBarrier
None of the batches reject normality, indicating that the Shapiro-Wilk test cannot be used to reject normality. 
We can generate a normal QQ-plot to get more insight into the log transformed batch 0.
<<figure3, fig.cap="QQ Plot of the log of batch 0", fig.show="asis", fig.pos = "h!", echo=FALSE>>=
qqnorm(log(batchB0$OUTCOME))
qqline(log(batchB0$OUTCOME))
@
\FloatBarrier
\subsection{Skewness and Kurtosis}
After performing the Shapiro-Wilk test, we have performed skewness and kurtosis tests, to get some insights in what way the transformed data follows normality. In most cases the skewness is a bit too high, while in other cases the kurtosis is not in the range of 
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
library(e1071)
skewness_batches = list();
kurtosis_batches = list();
for (batch in all_batches) {
  Bi = dataset[dataset$BATCH == batch,]$LOGOUTCOME
  skewness_batches[batch] <- e1071::skewness(Bi, type=2)
  kurtosis_batches[batch] <- e1071::kurtosis(Bi, type=2)
}
kurtosis_skewness = data.frame("kurtosis"= unlist(kurtosis_batches), "skewness" = unlist(skewness_batches))
library(xtable)
xtable(kurtosis_skewness, digits = c(0,3,3))
@
\FloatBarrier
Kurtosis and skewness tests are also formalized in the Jarque-Bera test, which tests if the skewness is close to zero and the kurtosis close to three. The p-value of the Jarque-Bera test is above $0.01$ for all batches, so we cannot reject the normality hypothesis based on skewness and kurtosis. Both the Shapiro-Wilk test and Jarque-Bera indicate that assuming normality on the batches is not rejected and therefore we will assume an underlying normal distribution for the following tests. It must also be noted that the t-test is robust against data that deviates somewhat from normality, so our assumption at least for that test is reasonable.
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
library(moments)
batches_jarque = list()
for (batch in all_batches) {
  Bi = dataset[dataset$BATCH == batch,]$LOGOUTCOME
  batches_jarque[batch] <- as.numeric(unlist(jarque.test(Bi))["p.value"])
}
jarque_frame = data.frame("Jarque-Bera"= unlist(batches_jarque))
library(xtable)
xtable(jarque_frame, digits=c(0,4))
@
\FloatBarrier
Kurtosis and skewness tests are also formalized in the Jarque-Bera test, which tests if the skewness is close to zero and the kurtosis close to three. The p-value of the Jarque-Bera test is above $0.01$ for all batches, so we cannot reject the normality hypothesis based on skewness and kurtosis. Both the Shapiro-Wilk test and Jarque-Bera indicate that assuming normality on the batches is not rejected and therefore we will assume an underlying normal distribution for the following tests. It must also be noted that the t-test is robust against data that deviates somewhat from normality, so our assumption at least for that test is reasonable.It must also be noted that the t-test is robust against data that deviates somewhat from normality, so our assumption at least for that test is reasonable.
\subsubsection{T-Test}
Performing the Barlett's tests gives us a p-value of $\Sexpr{as.numeric(unlist(bartlett.test(log(dataset$OUTCOME)~dataset$BATCH))["p.value"])} < 0.05$. This rejects the null hypothesis that all the batches have equal variance. This implies that we have to perform a t-test that assumes unequal variances. Batch seven has one missing value, which should not be a problem for a t-test.\\
The results of the t-tests can be found in the following table:
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
ttests_batches = list()
for (batch in batches) {
  ttests_batches[batch] <- t.test(batchB0$LOGOUTCOME, dataset[dataset$BATCH == batch,]$LOGOUTCOME,
                                  var.equal = FALSE, alternative = "less")$p.value
}
ttest_log_frame = data.frame("p-value"=unlist(ttests_batches))
library(xtable)
xtable(ttest_log_frame, digits=c(0,4))
@
\FloatBarrier
The results indicate that batch three has a mean that is significanlty different from the mean of the unaffected batch, since its p-value is less than $0.01$. This could indicate that this batch is affected.
\subsubsection{Variance testing}
After performing an F-test that compares all the batches with batch 0, we have found the following results:
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
vartestvalues = list()
for (batch in batches) {
  vartestvalues[batch] <- var.test(batchB0$LOGOUTCOME, dataset[dataset$BATCH == batch,]$LOGOUTCOME)$p.value
}
var_log_frame = data.frame("F-test"=unlist(vartestvalues))
library(xtable)
xtable(var_log_frame,digits=c(0,3))
@
\FloatBarrier
These results indicate that batch four has different properties than the other batches.
\subsubsection{Outliers}
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
library(outliers)
grubbsMin = list(`min`=c(),`p-value`=c());
grubbsMax = list(`max`=c(),`p-value`=c());
for(batch in batches) {
  Bi = dataset[dataset$BATCH == batch,]$OUTCOME;
  logBi = dataset[dataset$BATCH == batch,]$LOGOUTCOME;
  grubbsMin$min[batch] = min(Bi);
  grubbsMax$max[batch] = max(Bi);
  grubbsMin$`p-value`[batch] = grubbs.test(logBi, type=10, opposite=TRUE)$p.value;
  grubbsMax$`p-value`[batch] = grubbs.test(logBi, type=10)$p.value;
}
library(xtable);
xtable(as.data.frame(grubbsMin));
@
\FloatBarrier
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
library(xtable);
xtable(as.data.frame(grubbsMax));
@
\FloatBarrier
Both the extreme on the left and the right tail are not significantly big to reject them as an outlier. This indicates that no values can be indicated as errors due mistakes that people maked while measuring the amount of $\mu$g in the batches.
\subsection{Non-parametric tests}
\subsubsection{Wald-Wolfowitz Runs Test}
<<echo=FALSE, message=FALSE, warning=FALSE, results="hide">>=
library(adehabitatLT)
wawo_p <- wawotest(dataset$OUTCOME)["p"]
@
We have performed a Wald-Wolfowitz Runs test. We see that the p-value $=\Sexpr{wawo_p} < 0.05$ so we can reject that null hypothesis. This is an interesting result, because we know the data is obtained from the same source.
\subsubsection{Kolmogorov-Smirnov Test}
The results of the Kolmogorov-Smirnov test can be found in the following table. 
<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
ksB1 =  unlist(ks.test(batchB0$OUTCOME, batchB1$OUTCOME,         exact=TRUE)["p.value"])
ksB2 =  unlist(ks.test(batchB0$OUTCOME, batchB2$OUTCOME,         exact=TRUE)["p.value"])
ksB3 =  unlist(ks.test(batchB0$OUTCOME, batchB3$OUTCOME,         exact=TRUE)["p.value"])
ksB4 =  unlist(ks.test(batchB0$OUTCOME, batchB4$OUTCOME,         exact=TRUE)["p.value"])
ksB5 =  unlist(ks.test(batchB0$OUTCOME, batchB5$OUTCOME,         exact=TRUE)["p.value"])
ksB6 =  unlist(ks.test(batchB0$OUTCOME, batchB6$OUTCOME,         exact=TRUE)["p.value"])
ksB7 =  unlist(ks.test(batchB0$OUTCOME, batchB7$OUTCOME,         exact=TRUE)["p.value"])
ks_frame = data.frame(batch=c("B1", "B2", "B3", "B4", "B5", "B6", "B7"), 
                              "p-value"=c(ksB1, ksB2, ksB3, ksB4, ksB5, ksB6, ksB7))

library(xtable)
xtable(ks_frame, digits=c(0,0,4))
@
\FloatBarrier
None of the batches violate the null-hypothesis, since all p-values are larger than $0.01$. Note that the missing value in B7 is omitted in the test with B7 and replaced with the mean of all other values in B7 in the test with B7*. 
\subsubsection{Wilcoxon Rank-Sum Test}

<<echo=FALSE, warning=FALSE, message=FALSE, results="asis">>=
wilcoxB1 = unlist(wilcox.test(batchB0$OUTCOME, batchB1$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])
wilcoxB2 = unlist(wilcox.test(batchB0$OUTCOME, batchB2$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])
wilcoxB3 = unlist(wilcox.test(batchB0$OUTCOME, batchB3$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])
wilcoxB4 = unlist(wilcox.test(batchB0$OUTCOME, batchB4$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])
wilcoxB5 = unlist(wilcox.test(batchB0$OUTCOME, batchB5$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])
wilcoxB6 = unlist(wilcox.test(batchB0$OUTCOME, batchB6$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])
wilcoxB7 = unlist(wilcox.test(batchB0$OUTCOME, batchB7$OUTCOME,
                              paired=FALSE, correct=FALSE, exact=TRUE, alternative="less")["p.value"])

wilcox_frame = data.frame(batch=c("B1", "B2", "B3", "B4", "B5", "B6", "B7"), 
                          "p-value"=c(wilcoxB1, wilcoxB2, wilcoxB3, wilcoxB4, wilcoxB5, wilcoxB6,
                                      wilcoxB7))

library(xtable)
xtable(wilcox_frame, digits=c(0,0,4))
@
\FloatBarrier
We can observe that the p-value for batch 3 $= \Sexpr{wilcoxB3} < 0.01$ and so for batch 3 we reject the null hypothesis. The other batches do not deviate significantly from batch zero.
\newpage
\section{Conclusion}
If we consider the results, we see that batch three fails both the two-sided t-test and the Wilcoxon Rank-Sum Test. We have hypothesized that we expect some kind of location shift of the distribution towards a higher outcome. Both the Wilcoxon Rank-Sum Test and t-test are tests that investigate whether such a shift has taken place and by rejecting the null hypothesis they indicate that batch three indeed has shifted towards a higher amount of silicones in its batch. Because of this reason, we advice you to not sell batch three, since we highly expect that batch three is affected by the silicones.\\\\
Batch two and batch seven are also highly suspicious. Both batches pass the Wilcoxon Rank-Sum Test and t-test with a p-value very close to the critical value. It could be wise to do some further investigation on these two batches to get some more insight if the batches are contaminated.\\\\
If we consider the other tests, we see that batch four does not pass the homogeneity tests. This implies that the data from batch three has a different variance than batch 0. This is indeed the case, since the variance of batch three is quite low. As the only batch of the only batches it does not have a relatively high value that significantly stretches the variance. Because we only have very little data of each batch, it is probably the case that this high values are not randomly selected when gathering the data of the batches. Because batch four easily passes both the t-test and the Wilcoxon Rank-Sum Test we do not have any concerns that batch four is affected by silicones.\\\\
Since all the rest of the batches pass all the tests that could indicate an affection of silicons, we see no reason to state that batch one, two, four, five, six and seven are affected. Those batches should be suitable for sell.

\subsection{Pitfalls of our approach}
One of the pitfalls of our data analysis is the amount of data. Each batch has very little data, which increases the probability that the data is biased. This could mean that the comparison we have made with batch zero has been made with a highly biased data set. This would result in wrongly accepting or rejecting null hypothesis. \\\\
The other pitfall of our investigation is that we have only performed some conservative tests. Because we had to adjust the critical value, we increase the change that a type II error would occur. Especially batch two and batch seven could be the victim of a type II error, so it could be wise to get some more data of batch zero, two and seven to investigate even further whether they are clean or affected. As an addition to the tests we have already performed, it could be wise to also perform some ANOVA tests to see whether those tests indicate the same batch(es) as affected.

\end{document}
